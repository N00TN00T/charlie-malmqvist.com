<!DOCTYPE html>
<meta charset="utf-8"/>
<html>

	<head>
		<meta charset="utf-8"/>

		<link rel="stylesheet" href="common.css">
		<link rel="stylesheet" href="blog.css">

		<script src="https://code.jquery.com/jquery-3.4.1.min.js"></script> 
		<script src="nav.js"></script>
	</head>

	<header>
		<nav class="nav_top"></nav>
	</header>

	<body>
		<div class="article-container">
			<div class="article-section">
				<div class="article-content">
					<h1>[2020-05-02] Shaders & Lighting</h1>
					<div class="article-item">
						<p>
							The Wizzy demo game was looking a bit dull, so I figured it was time to showcase
							custom shaders and make it more interesting visually. This was also a good opportunity
							to try out using custom shading with the fresh pipeline API 
							(see earlier post <a class="link" href="#new-wizzy-2d-renderer">New Wizzy 2D Renderer</a>).
							While thinking of ideas for what visual effect to add, I realized that there is a pretty big limitation
							for our renderer. Since we're rendering it batches, we use an attribute layout to pass data per object per vertex,
							and we don't have any way to add to this layout; there is no way to send custom data per object. This is something
							for me to solve in the future so I decided to just implement some simple 2D lighting. Light data is consistent
							for all objects, so we can just upload it in uniforms each frame before rendering.
						</p>

						<p>
							To achieve simple 2D lighting there were a few things I needed to do: Write a custom shader, Load the shader and upload light data every frame.
						</p>
						<h3>The Shader</h3>
						<p>
							To write the shader I started of with a basic template 2D shader (found 
							<a href="Wizzy/texture2d.wzsdr">here</a>) which is just the same as the default
							Renderer2D fallback shader that is used when no custom shader is specified. Implementing
							lighting was not a whole lot of work. Basically all I needed was a light position and from there
							I could calculate the distance between the vertex and light position and determine the strength of its color.
							This, plus some properties to make it more interesting, was implemented with just a few lines.<br>
							I set the uniforms in the vertex shader:
							<div class="code">
								<pre>
									<code>
uniform float u_ambient = 0.1;
uniform vec2 u_lightPos;
uniform vec4 u_lightColor = vec4(1.0, 1.0, 1.0, 1.0);
uniform float u_intensity = 1.0;
uniform float u_radius = 300.f;
									</code>
								</pre>
							</div>
							<br>
							And use them to calculate the color based on the distance in the fragment shader:
							<div class="code">
								<pre>
									<code>
void main() {

	float distRatio = 1.0 - (length(lightPos - position) / (radius * 2.0));

	// Set the light color based on distance & intensity (with a minimum of ambient)
	fragColor = max(distRatio * lightColor * intensity, vec4(vec3(ambient), 1.0));

	vec4 textureColor = texture(u_textures[int(round(location))], uv);

	// Apply texture color
	fragColor *= color * textureColor;
}
									</code>
								</pre>
							</div>
						</p>

						
						
						<p>
							The Wizzy GitHub Repository can be found <a class="link" href="https://github.com/N00TN00T/Wizzy">here</a>.
						</p>
					</div>
				</div>
			</div>
			<div class="article-section">
				<div class="article-content">
					<h1>[2020-05-02] First Wizzy Game! (Breakout)</h1>
					<div class="article-item">
						<p>
							I made a simple breakout game that will constantly be expanded on during the development to showcase 
						the features of Wizzy. It's made using the ECS system. I also implemented live resource syncing, which can be seen in this sample video:
						</p>

						<iframe src="https://www.youtube.com/embed/aLt312gDOxY" width="640" height="480"></iframe><br>
						
						<p>
							The Wizzy GitHub Repository can be found <a class="link" href="https://github.com/N00TN00T/Wizzy">here</a>.
						</p>
					</div>
				</div>
			</div>
			<div class="article-section">
				<div class="article-content">
					<h1 id="new-wizzy-2d-renderer">[2020-04-29] New Wizzy 2D Renderer</h1>
					<div class="article-item">
						<p>
							I was playing around with the 2D renderer and wanted to use different shaders on
							different objects in the scene while also rendering them to different RenderTargets. 
							The shader was set in Renderer2D::Begin(), while the RenderTarget was used as a handle to 
							a batch in the renderer so it had to be passed in every Renderer2D function. Altough every 
							combination of shader and rendertarget needs to be its own batch, the api can be improved to
							make things easier. So, I decided to create a Pipeline struct that will keep track of its own batch
							and lets the user customize it by setting its shader, rendertarget, viewmatrix etc. The final version ended
							up looking like this:</p>
							<img src="media/rendererpipeline_001.png"><br>
							<p>
							I decided to make it a subclass and friend of Renderer2D. This way I can hide things from the user,
							like the vertexbuffer and vertexarray, but still exposing it to Renderer2D. This will make for a pretty
							clean API where the type is Renderer2D::Pipeline, which will let me make a Renderer::Pipeline
							type for when I'll implemented 3D rendering. Now, instead of taking in the shader in Renderer2D::Begin()
							and the rendertarget in every Renderer2D function call, the API looks more like this:</p>
							<img src="media/new_renderer_api_001.png"><br>
							<p>
								Here's what the code would look like to load a texture and render it to the screen:
							</p>
							<img src="media/renderer_api_001.png"><br>
							<p>
								But if we wanted to render this texture with a custom shader and/or to a specific rendertarget,
								we would only need to add a couple of lines to load the shader, create the rendertarget and assign
								them to the pipeline:
							</p>
							<img src="media/renderer_api_advanced_001.png"><br>
							<p>
								And while I was at reworking the renderer API, I also made a change I've been planning on doing for a while which was to
								allocated the batch buffer in the RAM and upload it to the vertex buffer instead of mapping it from the
								GPU to the RAM and then uploading it again. (Under the hood - use glSubBufferData instead of glMapBuffer).
								So with all these new changes I made a stress test for the renderer and managed to to render 100k quads at 60fps.
								<br>I also fixed the font rendering which works way better with the new API. Here's the result:
							</p>
							<iframe src="https://www.youtube.com/embed/w3gj0DWNbsI" width="640" height="480"></iframe><br>
							<p>
								The Wizzy GitHub Repository can be found <a class="link" href="https://github.com/N00TN00T/Wizzy">here</a>.
							</p>
					</div>
				</div>
			</div>
		</div>
	</body>

</html>











